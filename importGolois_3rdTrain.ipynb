{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "importGolois_3rdTrain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldvZjK8YrTVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b62773b-b114-4ea3-af82-12aa6997c507"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNxDy5hTfHs_"
      },
      "source": [
        "%cd /content/drive/MyDrive/cours/iasd-deep-golois/project/\n",
        "!pip install pybind11\n",
        "!chmod 777 ./compile.sh\n",
        "!./compile.sh\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVnZETentMAk"
      },
      "source": [
        "!cp golois.cpython-36m-x86_64-linux-gnu.so golois.so"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W4-yOt_TSVp"
      },
      "source": [
        "!pip install hyperas\n",
        "!pip install hyperopt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--_jqLjxcMNo"
      },
      "source": [
        "!pip install mlflow --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJVlA8LLYWjg"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import golois"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ1AXZCfZlt8"
      },
      "source": [
        "# HyperOpt exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIULroPsZ6qd"
      },
      "source": [
        "def bottleneck_block(x, hpo, expand, squeeze=64):\n",
        "    m = layers.Conv2D(expand, (1,1), kernel_regularizer=regularizers.l2(0.000328), use_bias = False)(x)\n",
        "    m = layers.BatchNormalization()(m)\n",
        "    m = layers.LeakyReLU(alpha=float(hpo[\"leakly_alpha\"]))(m) # layers.Activation('relu')(m)\n",
        "    m = layers.DepthwiseConv2D((3,3), padding='same', kernel_regularizer=regularizers.l2(0.000328), use_bias = False)(m)\n",
        "    m = layers.BatchNormalization()(m)\n",
        "    m = layers.LeakyReLU(alpha=float(hpo[\"leakly_alpha\"]))(m) #layers.Activation('relu')(m)\n",
        "    m = layers.Conv2D(squeeze, (1,1), kernel_regularizer=regularizers.l2(0.000328), use_bias = False)(m)\n",
        "    m = layers.BatchNormalization()(m)\n",
        "    return layers.Add()([m, x])\n",
        "\n",
        "# hpo provides the parameter values\n",
        "def create_model(hpo):\n",
        "  planes = 21\n",
        "  moves = 361\n",
        "  N = 100000\n",
        "  epochs = 10\n",
        "  batch= 128\n",
        "\n",
        "  filters = 64\n",
        "  trunk = filters\n",
        "\n",
        "  input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "  input_data = input_data.astype ('float32')\n",
        "\n",
        "  policy = np.random.randint(moves, size=(N,))\n",
        "  policy = keras.utils.to_categorical (policy)\n",
        "\n",
        "  value = np.random.randint(2, size=(N,))\n",
        "  value = value.astype ('float32')\n",
        "\n",
        "  end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "  end = end.astype ('float32')\n",
        "\n",
        "  groups = np.zeros((N, 19, 19, 1))\n",
        "  groups = groups.astype ('float32')\n",
        "\n",
        "  print (\"getValidation\", flush = True)\n",
        "  golois.getValidation (input_data, policy, value, end)\n",
        "\n",
        "  input = keras.Input(shape=(19, 19, planes), name='board')\n",
        "\n",
        "  # tester leaky relu, \n",
        "  x = layers.Conv2D(trunk, 1, activation='relu', padding='same')(input)\n",
        "\n",
        "  for i in range (33+1):\n",
        "      x = bottleneck_block(x, hpo, 201, trunk)\n",
        "\n",
        "  # fully convolutional, no dense layer\n",
        "  policy_head = layers.Conv2D(1, 1, activation='relu', padding='same',use_bias = False,kernel_regularizer=regularizers.l2(0.00048))(x)\n",
        "  policy_head = layers.Flatten()(policy_head)\n",
        "  policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "\n",
        "  value_head = layers.GlobalAveragePooling2D()(x)\n",
        "  value_head = layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l2(0.00048))(value_head)\n",
        "  value_head = layers.Dense(1, activation='sigmoid', name='value',kernel_regularizer=regularizers.l2(0.00048))(value_head)\n",
        "\n",
        "  model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYuF5FN4ZpOw"
      },
      "source": [
        "def runNN(hpo):\n",
        "\n",
        "  # Need to include the TF import due to serialization issues\n",
        "  import tensorflow as tf\n",
        "  \n",
        "  planes = 21\n",
        "  moves = 361\n",
        "  N = 100000\n",
        "  epochs = 10\n",
        "  batch= 128\n",
        "\n",
        "  input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "  input_data = input_data.astype ('float32')\n",
        "\n",
        "  policy = np.random.randint(moves, size=(N,))\n",
        "  policy = keras.utils.to_categorical (policy)\n",
        "\n",
        "  value = np.random.randint(2, size=(N,))\n",
        "  value = value.astype ('float32')\n",
        "\n",
        "  end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "  end = end.astype ('float32')\n",
        "\n",
        "  groups = np.zeros((N, 19, 19, 1))\n",
        "  groups = groups.astype ('float32')\n",
        "\n",
        "  # create the model given the hpo parameters\n",
        "  model = create_model(hpo)\n",
        " \n",
        "  model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
        "              loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "              loss_weights={'policy' : 1.0, 'value' : 1.0},\n",
        "              metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "  \n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                                patience=5, min_lr=0.000005)\n",
        "\n",
        "  for i in range (1, epochs + 1):\n",
        "    # print ('epoch ' + str (i))\n",
        "    golois.getBatch (input_data, policy, value, end, groups)\n",
        "    history = model.fit(input_data,\n",
        "                        {'policy': policy, 'value': value}, \n",
        "                        epochs=1, \n",
        "                        callbacks=[reduce_lr], # lr_callback, cp_callback],\n",
        "                        batch_size=batch)\n",
        "    if (i % 10 == 0):\n",
        "        golois.getValidation (input_data, policy, value, end)\n",
        "        val = model.evaluate (input_data,\n",
        "                              [policy, value], verbose = 0, batch_size=batch)\n",
        "        print (\"val =\", val)\n",
        "\n",
        "  # model.save ('tmp.h5')\n",
        "\n",
        "  # objective metric\n",
        "  obj_metric =  3.0 * (history.history[\"value_loss\"][-1]) - history.history[\"policy_loss\"][-1]\n",
        "  print(\"-->\" + str(obj_metric))\n",
        "  return {\"loss\": obj_metric, \"status\": STATUS_OK}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8CI-aBZbhUb"
      },
      "source": [
        "%%capture\n",
        "\n",
        "import os\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import golois\n",
        "import mlflow\n",
        "import mlflow.keras\n",
        "from hyperopt import fmin, hp, tpe, STATUS_OK, Trials\n",
        "\n",
        "tf.random.set_seed(42)\n",
        " \n",
        "space = {\n",
        "  # \"L2_regul\": hp.uniform(\"l2_rate\", 0.00048, 0.00048), # useless\n",
        "  \"leakly_alpha\": hp.uniform(\"leakly_alpha\", 0.0, 0.2)\n",
        "  # \"activation\": hp.uniform(\"alpha_rate\", 0.0, 0.1)\n",
        " }\n",
        " \n",
        "colab_trials = Trials()\n",
        " \n",
        "# see mlflow auto logging \n",
        "np_rstate = np.random.RandomState(42)\n",
        "\n",
        "with mlflow.start_run():\n",
        "  \n",
        "  best_hyperparam = fmin(fn=runNN, \n",
        "                         space=space, \n",
        "                         algo=tpe.suggest, #top !\n",
        "                         max_evals=5, \n",
        "                         trials=colab_trials,\n",
        "                         rstate=np_rstate)\n",
        " \n",
        "best_hyperparam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBYo7tI2YtwO"
      },
      "source": [
        "import pickle\n",
        "with open(\"test6.hyperopt\", \"wb\") as f:\n",
        "        pickle.dump(colab_trials, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzLJPAC1WfLk"
      },
      "source": [
        "best_hyperparam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqxLzTSA1D1h"
      },
      "source": [
        "# Notes & tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YK7bUcRcdCo"
      },
      "source": [
        "# JS code to append in Chrome console to keep the Colab session live\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"#help-menu-button\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}